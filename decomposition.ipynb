{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbfd5a-af80-4f75-8cbd-e9e8f42631fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "import os, time, random\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "from glob import glob\n",
    "import argparse\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "parser.add_argument('--batch_size', dest='batch_size', type=int, default=10, help='number of samples in one batch')\n",
    "parser.add_argument('--patch_size', dest='patch_size', type=int, default=48, help='patch size')\n",
    "parser.add_argument('--train_data_dir', dest='train_data_dir', default='./LOLdataset/our485', help='directory for training inputs')\n",
    "parser.add_argument('--train_result_dir', dest='train_result_dir', default='./decom_net_train_result/', help='directory for decomnet training results')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "batch_size = args.batch_size\n",
    "patch_size = args.patch_size\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "input_low = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 3], name='input_low')\n",
    "input_high = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 3], name='input_high')\n",
    "\n",
    "[R_low, I_low] = DecomNet(input_low)\n",
    "[R_high, I_high] = DecomNet(input_high)\n",
    "\n",
    "I_low_3 = tf.compat.v1.concat([I_low, I_low, I_low], axis=3)\n",
    "I_high_3 = tf.compat.v1.concat([I_high, I_high, I_high], axis=3)\n",
    "\n",
    "#network output\n",
    "output_R_low = R_low\n",
    "output_R_high = R_high\n",
    "output_I_low = I_low_3\n",
    "output_I_high = I_high_3\n",
    "\n",
    "# define loss\n",
    "\n",
    "def mutual_i_loss(input_I_low, input_I_high):\n",
    "    low_gradient_x = gradient(input_I_low, \"x\")\n",
    "    high_gradient_x = gradient(input_I_high, \"x\")\n",
    "    x_loss = (low_gradient_x + high_gradient_x)* tf.compat.v1.exp(-10*(low_gradient_x+high_gradient_x))\n",
    "    low_gradient_y = gradient(input_I_low, \"y\")\n",
    "    high_gradient_y = gradient(input_I_high, \"y\")\n",
    "    y_loss = (low_gradient_y + high_gradient_y) * tf.compat.v1.exp(-10*(low_gradient_y+high_gradient_y))\n",
    "    mutual_loss = tf.compat.v1.reduce_mean( x_loss + y_loss) \n",
    "    return mutual_loss\n",
    "\n",
    "def mutual_i_input_loss(input_I_low, input_im):\n",
    "    input_gray = tf.compat.v1.image.rgb_to_grayscale(input_im)\n",
    "    low_gradient_x = gradient(input_I_low, \"x\")\n",
    "    input_gradient_x = gradient(input_gray, \"x\")\n",
    "    x_loss = tf.compat.v1.abs(tf.compat.v1.div(low_gradient_x, tf.compat.v1.maximum(input_gradient_x, 0.01)))\n",
    "    low_gradient_y = gradient(input_I_low, \"y\")\n",
    "    input_gradient_y = gradient(input_gray, \"y\")\n",
    "    y_loss = tf.compat.v1.abs(tf.compat.v1.div(low_gradient_y, tf.compat.v1.maximum(input_gradient_y, 0.01)))\n",
    "    mut_loss = tf.compat.v1.reduce_mean(x_loss + y_loss) \n",
    "    return mut_loss\n",
    "\n",
    "recon_loss_low = tf.compat.v1.reduce_mean(tf.compat.v1.abs(R_low * I_low_3 -  input_low))\n",
    "recon_loss_high = tf.compat.v1.reduce_mean(tf.compat.v1.abs(R_high * I_high_3 - input_high))\n",
    "\n",
    "equal_R_loss = tf.compat.v1.reduce_mean(tf.compat.v1.abs(R_low - R_high))\n",
    "\n",
    "i_mutual_loss = mutual_i_loss(I_low, I_high)\n",
    "\n",
    "i_input_mutual_loss_high = mutual_i_input_loss(I_high, input_high)\n",
    "i_input_mutual_loss_low = mutual_i_input_loss(I_low, input_low)\n",
    "\n",
    "loss_Decom = 1*recon_loss_high + 1*recon_loss_low \\\n",
    "               + 0.009 * equal_R_loss + 0.2*i_mutual_loss \\\n",
    "             + 0.15* i_input_mutual_loss_high + 0.15* i_input_mutual_loss_low\n",
    "\n",
    "###\n",
    "lr = tf.compat.v1.placeholder(tf.compat.v1.float32, name='learning_rate')\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=lr, name='AdamOptimizer')\n",
    "var_Decom = [var for var in tf.compat.v1.trainable_variables() if 'DecomNet' in var.name]\n",
    "train_op_Decom = optimizer.minimize(loss_Decom, var_list = var_Decom)\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "saver_Decom = tf.compat.v1.train.Saver(var_list = var_Decom)\n",
    "print(\"[*] Initialize model successfully...\")\n",
    "\n",
    "#load data\n",
    "###train_data\n",
    "train_low_data = []\n",
    "train_high_data = []\n",
    "train_low_data_names = glob(args.train_data_dir + '/low/*.png') \n",
    "train_low_data_names.sort()\n",
    "train_high_data_names = glob(args.train_data_dir + '/high/*.png') \n",
    "train_high_data_names.sort()\n",
    "assert len(train_low_data_names) == len(train_high_data_names)\n",
    "print('[*] Number of training data: %d' % len(train_low_data_names))\n",
    "for idx in range(len(train_low_data_names)):\n",
    "    low_im = load_images(train_low_data_names[idx])\n",
    "    train_low_data.append(low_im)\n",
    "    high_im = load_images(train_high_data_names[idx])\n",
    "    train_high_data.append(high_im)\n",
    "###eval_data\n",
    "eval_low_data = []\n",
    "eval_high_data = []\n",
    "eval_low_data_name = glob('./LOLdataset/eval15/low/*.png')\n",
    "eval_low_data_name.sort()\n",
    "eval_high_data_name = glob('./LOLdataset/eval15/high/*.png*')\n",
    "eval_high_data_name.sort()\n",
    "for idx in range(len(eval_low_data_name)):\n",
    "    eval_low_im = load_images(eval_low_data_name[idx])\n",
    "    eval_low_data.append(eval_low_im)\n",
    "    eval_high_im = load_images(eval_high_data_name[idx])\n",
    "    eval_high_data.append(eval_high_im)\n",
    "\n",
    "\n",
    "epoch = 2500\n",
    "learning_rate = 0.0001\n",
    "\n",
    "sample_dir = args.train_result_dir\n",
    "if not os.path.isdir(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "eval_every_epoch = 500\n",
    "train_phase = 'decomposition'\n",
    "numBatch = len(train_low_data) // int(batch_size)\n",
    "train_op = train_op_Decom\n",
    "train_loss = loss_Decom\n",
    "saver = saver_Decom\n",
    "\n",
    "checkpoint_dir = './checkpoint/decom_net_retrain/'\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "ckpt=tf.compat.v1.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt:\n",
    "    print('loaded '+ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print('No decomnet pretrained model!')\n",
    "\n",
    "start_step = 0\n",
    "start_epoch = 0\n",
    "iter_num = 0\n",
    "\n",
    "print(\"[*] Start training for phase %s, with start epoch %d start iter %d : \" % (train_phase, start_epoch, iter_num))\n",
    "start_time = time.time()\n",
    "image_id = 0\n",
    "for epoch in range(start_epoch, epoch):\n",
    "    for batch_id in range(start_step, numBatch):\n",
    "        batch_input_low = np.zeros((batch_size, patch_size, patch_size, 3), dtype=\"float32\")\n",
    "        batch_input_high = np.zeros((batch_size, patch_size, patch_size, 3), dtype=\"float32\")\n",
    "        for patch_id in range(batch_size):\n",
    "            h, w, _ = train_low_data[image_id].shape\n",
    "            x = random.randint(0, h - patch_size)\n",
    "            y = random.randint(0, w - patch_size)\n",
    "            rand_mode = random.randint(0, 7)\n",
    "            batch_input_low[patch_id, :, :, :] = data_augmentation(train_low_data[image_id][x : x+patch_size, y : y+patch_size, :], rand_mode)\n",
    "            batch_input_high[patch_id, :, :, :] = data_augmentation(train_high_data[image_id][x : x+patch_size, y : y+patch_size, :], rand_mode)\n",
    "            image_id = (image_id + 1) % len(train_low_data)\n",
    "            if image_id == 0:\n",
    "                tmp = list(zip(train_low_data, train_high_data))\n",
    "                random.shuffle(tmp)\n",
    "                train_low_data, train_high_data  = zip(*tmp)\n",
    "\n",
    "        _, loss = sess.run([train_op, train_loss], feed_dict={input_low: batch_input_low, \\\n",
    "                                                              input_high: batch_input_high, \\\n",
    "                                                              lr: learning_rate})\n",
    "        print(\"%s Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.6f\" \\\n",
    "              % (train_phase, epoch + 1, batch_id + 1, numBatch, time.time() - start_time, loss))\n",
    "        iter_num += 1\n",
    "    if (epoch + 1) % eval_every_epoch == 0:\n",
    "        print(\"[*] Evaluating for phase %s / epoch %d...\" % (train_phase, epoch + 1))\n",
    "        for idx in range(len(eval_low_data)):\n",
    "            input_low_eval = np.expand_dims(eval_low_data[idx], axis=0)\n",
    "            result_1, result_2 = sess.run([output_R_low, output_I_low], feed_dict={input_low: input_low_eval})\n",
    "            save_images(os.path.join(sample_dir, 'low_%d_%d.png' % ( idx + 1, epoch + 1)), result_1, result_2)\n",
    "        for idx in range(len(eval_low_data)):\n",
    "            input_low_eval = np.expand_dims(eval_high_data[idx], axis=0)\n",
    "            result_11, result_22 = sess.run([output_R_high, output_I_high], feed_dict={input_high: input_low_eval})\n",
    "            save_images(os.path.join(sample_dir, 'high_%d_%d.png' % ( idx + 1, epoch + 1)), result_11, result_22)\n",
    "         \n",
    "    saver.save(sess, checkpoint_dir + 'model.ckpt')\n",
    "\n",
    "print(\"[*] Finish training for phase %s.\" % train_phase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976a09bc-c2a1-468f-b65d-c0a1cfc74436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/WYF/Infinova/超分辨率/KinD_plus/utils.py:76: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Initialize model successfully...\n",
      "[*] Number of training data: 481\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'PngImageFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f9cc0c2fb3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[*] Number of training data: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_low_data_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_low_data_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mlow_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_low_data_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mtrain_low_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mhigh_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_high_data_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Infinova/超分辨率/KinD_plus/utils.py\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mimg_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mimg_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'PngImageFile'"
     ]
    }
   ],
   "source": [
    "# File name: Decomposition_net_train.py\n",
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "import os, time, random\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "from glob import glob\n",
    "\n",
    "batch_size = 10\n",
    "patch_size = 48\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "input_low = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 3], name='input_low')\n",
    "input_high = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 3], name='input_high')\n",
    "\n",
    "[R_low, I_low] = DecomNet(input_low)\n",
    "[R_high, I_high] = DecomNet(input_high)\n",
    "\n",
    "I_low_3 = tf.compat.v1.concat([I_low, I_low, I_low], axis=3)\n",
    "I_high_3 = tf.compat.v1.concat([I_high, I_high, I_high], axis=3)\n",
    "\n",
    "#network output\n",
    "output_R_low = R_low\n",
    "output_R_high = R_high\n",
    "output_I_low = I_low_3\n",
    "output_I_high = I_high_3\n",
    "\n",
    "# define loss\n",
    "\n",
    "def mutual_i_loss(input_I_low, input_I_high):\n",
    "    low_gradient_x = gradient(input_I_low, \"x\")\n",
    "    high_gradient_x = gradient(input_I_high, \"x\")\n",
    "    x_loss = (low_gradient_x + high_gradient_x)* tf.compat.v1.exp(-10*(low_gradient_x+high_gradient_x))\n",
    "    low_gradient_y = gradient(input_I_low, \"y\")\n",
    "    high_gradient_y = gradient(input_I_high, \"y\")\n",
    "    y_loss = (low_gradient_y + high_gradient_y) * tf.compat.v1.exp(-10*(low_gradient_y+high_gradient_y))\n",
    "    mutual_loss = tf.compat.v1.reduce_mean( x_loss + y_loss) \n",
    "    return mutual_loss\n",
    "\n",
    "def mutual_i_input_loss(input_I_low, input_im):\n",
    "    input_gray = tf.compat.v1.image.rgb_to_grayscale(input_im)\n",
    "    low_gradient_x = gradient(input_I_low, \"x\")\n",
    "    input_gradient_x = gradient(input_gray, \"x\")\n",
    "    x_loss = tf.compat.v1.abs(tf.compat.v1.div(low_gradient_x, tf.compat.v1.maximum(input_gradient_x, 0.01)))\n",
    "    low_gradient_y = gradient(input_I_low, \"y\")\n",
    "    input_gradient_y = gradient(input_gray, \"y\")\n",
    "    y_loss = tf.compat.v1.abs(tf.compat.v1.div(low_gradient_y, tf.compat.v1.maximum(input_gradient_y, 0.01)))\n",
    "    mut_loss = tf.compat.v1.reduce_mean(x_loss + y_loss) \n",
    "    return mut_loss\n",
    "\n",
    "recon_loss_low = tf.compat.v1.reduce_mean(tf.compat.v1.abs(R_low * I_low_3 -  input_low))\n",
    "recon_loss_high = tf.compat.v1.reduce_mean(tf.compat.v1.abs(R_high * I_high_3 - input_high))\n",
    "\n",
    "equal_R_loss = tf.compat.v1.reduce_mean(tf.compat.v1.abs(R_low - R_high))\n",
    "\n",
    "i_mutual_loss = mutual_i_loss(I_low, I_high)\n",
    "\n",
    "i_input_mutual_loss_high = mutual_i_input_loss(I_high, input_high)\n",
    "i_input_mutual_loss_low = mutual_i_input_loss(I_low, input_low)\n",
    "\n",
    "loss_Decom = 1*recon_loss_high + 1*recon_loss_low \\\n",
    "               + 0.01 * equal_R_loss + 0.2*i_mutual_loss \\\n",
    "             + 0.15* i_input_mutual_loss_high + 0.15* i_input_mutual_loss_low\n",
    "\n",
    "###\n",
    "lr = tf.compat.v1.placeholder(tf.compat.v1.float32, name='learning_rate')\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=lr, name='AdamOptimizer')\n",
    "var_Decom = [var for var in tf.compat.v1.trainable_variables() if 'DecomNet' in var.name]\n",
    "\n",
    "train_op_Decom = optimizer.minimize(loss_Decom, var_list = var_Decom)\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "saver_Decom = tf.compat.v1.train.Saver(var_list = var_Decom)\n",
    "print(\"[*] Initialize model successfully...\")\n",
    "\n",
    "#load data\n",
    "###train_data\n",
    "train_low_data = []\n",
    "train_high_data = []\n",
    "train_low_data_names = glob('./LOLdataset/our485/low/*.png') \n",
    "train_low_data_names.sort()\n",
    "train_high_data_names = glob('./LOLdataset/our485/high/*.png') \n",
    "train_high_data_names.sort()\n",
    "assert len(train_low_data_names) == len(train_high_data_names)\n",
    "print('[*] Number of training data: %d' % len(train_low_data_names))\n",
    "for idx in range(len(train_low_data_names)):\n",
    "    low_im = load_images(train_low_data_names[idx])\n",
    "    train_low_data.append(low_im)\n",
    "    high_im = load_images(train_high_data_names[idx])\n",
    "    train_high_data.append(high_im)\n",
    "###eval_data\n",
    "eval_low_data = []\n",
    "eval_high_data = []\n",
    "eval_low_data_name = glob('./LOLdataset/eval15/low/*.png')\n",
    "eval_low_data_name.sort()\n",
    "eval_high_data_name = glob('./LOLdataset/eval15/high/*.png*')\n",
    "eval_high_data_name.sort()\n",
    "for idx in range(len(eval_low_data_name)):\n",
    "    eval_low_im = load_images(eval_low_data_name[idx])\n",
    "    eval_low_data.append(eval_low_im)\n",
    "    eval_high_im = load_images(eval_high_data_name[idx])\n",
    "    eval_high_data.append(eval_high_im)\n",
    "\n",
    "\n",
    "# epoch = 2000\n",
    "epoch = 200\n",
    "learning_rate = 0.0001\n",
    "\n",
    "sample_dir = './Decom_net_train/'\n",
    "if not os.path.isdir(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "eval_every_epoch = 200\n",
    "train_phase = 'decomposition'\n",
    "numBatch = len(train_low_data) // int(batch_size)\n",
    "train_op = train_op_Decom\n",
    "train_loss = loss_Decom\n",
    "saver = saver_Decom\n",
    "\n",
    "checkpoint_dir = './checkpoint/decom_net_train/'\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "ckpt=tf.compat.v1.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt:\n",
    "    print('loaded '+ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "\n",
    "start_step = 0\n",
    "start_epoch = 0\n",
    "iter_num = 0\n",
    "print(\"[*] Start training for phase %s, with start epoch %d start iter %d : \" % (train_phase, start_epoch, iter_num))\n",
    "\n",
    "start_time = time.time()\n",
    "image_id = 0\n",
    "for epoch in range(start_epoch, epoch):\n",
    "    for batch_id in range(start_step, numBatch):\n",
    "        batch_input_low = np.zeros((batch_size, patch_size, patch_size, 3), dtype=\"float32\")\n",
    "        batch_input_high = np.zeros((batch_size, patch_size, patch_size, 3), dtype=\"float32\")\n",
    "        for patch_id in range(batch_size):\n",
    "            h, w, _ = train_low_data[image_id].shape\n",
    "            x = random.randint(0, h - patch_size)\n",
    "            y = random.randint(0, w - patch_size)\n",
    "            rand_mode = random.randint(0, 7)\n",
    "            batch_input_low[patch_id, :, :, :] = data_augmentation(train_low_data[image_id][x : x+patch_size, y : y+patch_size, :], rand_mode)\n",
    "            batch_input_high[patch_id, :, :, :] = data_augmentation(train_high_data[image_id][x : x+patch_size, y : y+patch_size, :], rand_mode)\n",
    "            image_id = (image_id + 1) % len(train_low_data)\n",
    "            if image_id == 0:\n",
    "                tmp = list(zip(train_low_data, train_high_data))\n",
    "                random.shuffle(tmp)\n",
    "                train_low_data, train_high_data  = zip(*tmp)\n",
    "\n",
    "        _, loss = sess.run([train_op, train_loss], feed_dict={input_low: batch_input_low, \\\n",
    "                                                              input_high: batch_input_high, \\\n",
    "                                                              lr: learning_rate})\n",
    "        print(\"%s Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.6f\" \\\n",
    "              % (train_phase, epoch + 1, batch_id + 1, numBatch, time.time() - start_time, loss))\n",
    "        iter_num += 1\n",
    "    if (epoch + 1) % eval_every_epoch == 0:\n",
    "        print(\"[*] Evaluating for phase %s / epoch %d...\" % (train_phase, epoch + 1))\n",
    "        for idx in range(len(eval_low_data)):\n",
    "            input_low_eval = np.expand_dims(eval_low_data[idx], axis=0)\n",
    "            result_1, result_2 = sess.run([output_R_low, output_I_low], feed_dict={input_low: input_low_eval})\n",
    "            save_images(os.path.join(sample_dir, 'low_%d_%d.png' % ( idx + 1, epoch + 1)), result_1, result_2)\n",
    "        for idx in range(len(eval_high_data)):\n",
    "            input_high_eval = np.expand_dims(eval_high_data[idx], axis=0)\n",
    "            result_11, result_22 = sess.run([output_R_high, output_I_high], feed_dict={input_high: input_high_eval})\n",
    "            save_images(os.path.join(sample_dir, 'high_%d_%d.png' % ( idx + 1, epoch + 1)), result_11, result_22)\n",
    "         \n",
    "    saver.save(sess, checkpoint_dir + 'model.ckpt')\n",
    "\n",
    "print(\"[*] Finish training for phase %s.\" % train_phase)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec6c73-97a9-4194-ac6f-18fce43dc3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
